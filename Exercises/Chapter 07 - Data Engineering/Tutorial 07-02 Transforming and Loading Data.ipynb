{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9216a54",
   "metadata": {},
   "source": [
    "# Tutorial 07-02 Transforming and Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce388a41",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Repeat Extract Logic from Tutorial 07-01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afdac25",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In the previous tutorial, we extracted data from an API and converted it into a pandas DataFrame.  Now we can put some transformations in place and put everything together.  \n",
    "\n",
    "While we're copying our code over this time, let's take an opportunity to make our code a bit more reusable.  In the earlier chapters of this book, we brought up the concept of functional programming.  Now we can put that concept into practice.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f908cc1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1.  Create a function.\n",
    "The one big thing we can abstract away is the extraction of data and conversion to a DataFrame.  There wasn't anything specific to our use-case in that (aside from the specific URL we formatted).  All that logic about getting a response from the URL, converting to Python data types, then ultimately to a DataFrame is totally repeatable for other URLs.  Now you'll turn that into a function we can use here and reuse elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25d17b0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def extract_to_df(url):\n",
    "    '''\n",
    "    TODO - write docstring\n",
    "    '''\n",
    "\n",
    "    # Request data from the API\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Convert the response to JSON\n",
    "    response_text = response.text\n",
    "\n",
    "    # Convert JSON to a Python data types (lists/dictionaries)\n",
    "    results_list = json.loads(response_text)\n",
    "\n",
    "    # Convert the Python lists/dictionaries to a Pandas DataFrame\n",
    "    df = pandas.DataFrame(results_list)\n",
    "\n",
    "    # Return the DataFrame\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ff40b3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The majority of the remaining logic we had was specific to our use case and might not be worth abstracting away into a function at this point.  The repeatable functionality you turned into a function will make your code a bit cleaner though.  Notice the last line of your code block below calls the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c7a5b0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 2.  Reformat the code from the previous exercise\n",
    "Now you'll consolidate and clean up the code from the previous exercise.  You can go back through all the cells and copy the code over individually or you can use the code block below.  Either way, the goal would be to start with your import statements and end with a DataFrame of data that you can work with further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4577b7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import arcgis\n",
    "\n",
    "# base url for the data\n",
    "url = \"https://data.sfgov.org/resource/vw6y-z8j6.json\"\n",
    "\n",
    "# build the field list\n",
    "field_list = [\n",
    "    'service_request_id',\n",
    "    'requested_datetime',\n",
    "    'status_notes',\n",
    "    'service_name',\n",
    "    'service_subtype',\n",
    "    'lat',\n",
    "    'long',\n",
    "    'neighborhoods_sffind_boundaries',\n",
    "    'source',\n",
    "    'supervisor_district',\n",
    "    'media_url',\n",
    "    'point'\n",
    "]\n",
    "fields = \"$select=\" + \",\".join(field_list)\n",
    "\n",
    "# build the where statement\n",
    "now = datetime.datetime.now()\n",
    "start_date = now - datetime.timedelta(days=7)\n",
    "\n",
    "# Set the time to midnight\n",
    "midnight = datetime.time()\n",
    "\n",
    "# Combine the date and time\n",
    "start_day_midnight = datetime.datetime.combine(start_date, midnight)\n",
    "start_day_string = start_day_midnight.strftime('%Y-%m-%dT%H:%M:%S.%f') \n",
    "where = f\"$where=status_description='Open' and requested_datetime > '{start_day_string}'\"\n",
    "\n",
    "# set a record limit\n",
    "limit = \"&$limit=10000\"\n",
    "\n",
    "# combine the url components\n",
    "full_url = url+\"?\" + fields + \"&\" + where + limit\n",
    "\n",
    "# call our function to extract and convert to a DataFrame\n",
    "df = extract_to_df(full_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b7bf14",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a42c74",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Condition the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb75e97",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1.  Write a lambda function.\n",
    "Now you'll get your data ready to summarize.  If you want to summarize counts of records with specific service name values, you can add new columns to the raw data to summarize.  You'll use a common pattern combining a pandas method and a core Pandas concept called a *lambda function*.\n",
    "\n",
    "Lambda functions are short one-line functions that we can use to execute relatively simple logic without having to define a function.  Let's take the following example of a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c52448",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def street_cleaning(value):\n",
    "    if value == 'Street and Sidewalk Cleaning':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "print(street_cleaning('Street and Sidewalk Cleaning'))\n",
    "print(street_cleaning('some other string'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60680ece",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You've defined a function that returns a 1 if it receives the specific string \"Street and Sidewalk Cleaning\".  If it receives anything else, it returns a 0.  This is going to be really useful for summary purposes later.  You'll have to do this multiple times though, so writing it in a more concise way would be helpful.  This is where the lambda function comes in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e4f225",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lambda_func = lambda x: 1 if x == 'Street and Sidewalk Cleaning' else 0\n",
    "\n",
    "print(lambda_func('Street and Sidewalk Cleaning'))\n",
    "print(lambda_func('some other string'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8477dca4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 2.  Apply that lambda function to a column of data.\n",
    "This gave you the same values as the more verbose function we defined previously, but was defined all in one line.  Now you can combine that with a pandas method called **apply** that applies your function to all the values in a column (or Series in pandas terminology)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cfe556",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['service_name'].apply(\n",
    "    lambda r: 1 if r== 'Street and Sidewalk Cleaning' else 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4240f91",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that this returns another column.  You can now save this new column as a column in our DataFrame.  You can also do this with the other string values we're interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bda527",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 3.  Create new columns using lambda functions and the apply method\n",
    "Now you'll use that same methodology to create multiple new columns that you'll use for summary purposes later.  If you're summarizing data by groups, sometimes it's also handy to have a column that just has a 1 for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731e306e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# street/sidewalk cleaning yes/no\n",
    "df['street_sidewalk_cleaning'] = df['service_name'].apply(\n",
    "    lambda r: 1 if r== 'Street and Sidewalk Cleaning' else 0\n",
    ")\n",
    "\n",
    "# graffiti yes/no\n",
    "df['graffiti'] = df['service_name'].apply(\n",
    "    lambda r: 1 if r== 'Graffiti' else 0\n",
    ")\n",
    "\n",
    "# counter column for total cases\n",
    "df['total_cases'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7940088",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[['service_name','street_sidewalk_cleaning','graffiti','total_cases']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe13b91",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Summarize By Neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dacf8cd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that you've gotten our raw data directly from the source, we can continue our transformation by summarizing the data by neighborhood.  This will allow you to join with the spatial data going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a495871",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1.  Use Pandas to group and summarize the data\n",
    "Pandas DataFrames have a built-in method called `groupby()`.  This accepts a column (or list of columns) to group by.  It returns a new object that isn't super useful on its own.  You'll need to use an aggregation method on that new object.  There are many, but you can use `.agg()` in this case so that you can specify which columns you want to summarize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0687c3f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_neighborhood = df.groupby(\"neighborhoods_sffind_boundaries\").agg(\n",
    "    {\n",
    "        \"total_cases\": \"sum\",\n",
    "        \"street_sidewalk_cleaning\": \"sum\",\n",
    "        \"graffiti\": \"sum\"\n",
    "    }\n",
    ")\n",
    "df_neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d484dd",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Read Spatial Data and Merge with Summary Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b5d7a9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1.  Read spatial data from a feature class.\n",
    "Now you'll create a Spatially Enabled DataFrame using neighborhood data.  This is using the `spatial` accessor that comes with the `arcgis` package.  You'll use the `from_featureclass()` method to read a local feature class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60227650",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sedf_neighborhoods = pandas.DataFrame.spatial.from_featureclass(\n",
    "    \"../Chapter 06/Tutorial_06_02.gdb/SF_Find_Neighborhoods\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271bc438",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 2.  Merge non-spatial summary with spatial data.\n",
    "You're going to use a pandas method called **merge** here.  If you need to review this topic there's a more in-depth discussion in the **Data Manipulation** chapter, but it's basically pandas' version of a table join.  You're going to join your geometry with your summarized data and create a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaa5b50",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sedf_merge = sedf_neighborhoods.merge(\n",
    "    df_neighborhood, \n",
    "    how = 'inner', \n",
    "    left_on = 'name', \n",
    "    right_on = 'neighborhoods_sffind_boundaries'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0250057",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Write the Data to an Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c29acb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1.  Write joined data to a feature class.\n",
    "The \"Load\" portion of an ETL process can take several forms.  We're going to choose to overwrite here and discuss other options following the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc47acb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sedf_merge.spatial.to_featureclass(\n",
    "    \"../Chapter 06/Tutorial_06_02.gdb/sf_311_cases_prev_7_days\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73b3856",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
