{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9216a54",
   "metadata": {},
   "source": [
    "# Tutorial 07-02 Transforming and Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce388a41",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 1. Repeat Extract Logic from Tutorial 07-01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afdac25",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In the previous tutorial, we extracted data from an API and converted it into a pandas DataFrame.  Now we can put some transformations in place and put everything together.  \n",
    "\n",
    "While we're copying our code over this time, let's take an opportunity to make our code a bit more reusable.  In the earlier chapters of this book, we brought up the concept of functional programming.  Now we can put that concept into practice.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f908cc1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The one big thing we can abstract away is the extraction of data and conversion to a DataFrame.  There wasn't anything specific to our use-case in that (aside from the specific URL we formatted).  All that logic about getting a response from the URL, converting to Python data types, then ultimately to a DataFrame is totally repeatable for other URLs.  Let's turn that into a function we can use here and reuse elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25d17b0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def extract_to_df(url):\n",
    "    '''\n",
    "    TODO - write docstring\n",
    "    '''\n",
    "\n",
    "    # Request data from the API\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Convert the response to JSON\n",
    "    response_text = response.text\n",
    "\n",
    "    # Convert JSON to a Python data types (lists/dictionaries)\n",
    "    results_list = json.loads(response_text)\n",
    "\n",
    "    # Convert the Python lists/dictionaries to a Pandas DataFrame\n",
    "    df = pandas.DataFrame(results_list)\n",
    "\n",
    "    # Return the DataFrame\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ff40b3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The majority of the remaining logic we had was specific to our use case and might not be worth abstracting away into a function at this point.  The repeatable functionality we turned into a function will make our code a bit cleaner though.  Notice the last line of our code block below calls the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4577b7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import arcgis\n",
    "\n",
    "# base url for the data\n",
    "url = \"https://data.sfgov.org/resource/vw6y-z8j6.json\"\n",
    "\n",
    "# build the field list\n",
    "field_list = [\n",
    "    'service_request_id',\n",
    "    'requested_datetime',\n",
    "    'status_notes',\n",
    "    'service_name',\n",
    "    'service_subtype',\n",
    "    'lat',\n",
    "    'long',\n",
    "    'neighborhoods_sffind_boundaries',\n",
    "    'source',\n",
    "    'supervisor_district',\n",
    "    'media_url',\n",
    "    'point'\n",
    "]\n",
    "fields = \"$select=\" + \",\".join(field_list)\n",
    "\n",
    "# build the where statement\n",
    "now = datetime.datetime.now()\n",
    "start_date = now - datetime.timedelta(days=7)\n",
    "\n",
    "# Set the time to midnight\n",
    "midnight = datetime.time()\n",
    "\n",
    "# Combine the date and time\n",
    "start_day_midnight = datetime.datetime.combine(start_date, midnight)\n",
    "start_day_string = start_day_midnight.strftime('%Y-%m-%dT%H:%M:%S.%f') \n",
    "where = f\"$where=status_description='Open' and requested_datetime > '{start_day_string}'\"\n",
    "\n",
    "# set a record limit\n",
    "limit = \"&$limit=10000\"\n",
    "\n",
    "# combine the url components\n",
    "full_url = url+\"?\" + fields + \"&\" + where + limit\n",
    "\n",
    "# call our function to extract and convert to a DataFrame\n",
    "df = extract_to_df(full_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b7bf14",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a42c74",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 2.  Condition the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb75e97",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's get our data ready to summarize.  If we want to summarize counts of records with specific service name values, we can add new columns to the raw data to summarize.  We'll use a common pattern combining a pandas method and a core Pandas concept called a *lambda function*.\n",
    "\n",
    "Lambda functions are short one-line functions that we can use to execute relatively simple logic without having to define a function.  Let's take the following example of a function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60680ece",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We've defined a function that returns a 1 if it receives the specific string \"Street and Sidewalk Cleaning\".  If it receives anything else, it returns a 0.  This is going to be really useful for summary purposes later.  We'll have to do this multiple times though, so writing it in a more concise way would be helpful.  This is where the lambda function comes in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c52448",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def street_cleaning(value):\n",
    "    if value == 'Street and Sidewalk Cleaning':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "print(street_cleaning('Street and Sidewalk Cleaning'))\n",
    "print(street_cleaning('some other string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e4f225",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lambda_func = lambda x: 1 if x == 'Street and Sidewalk Cleaning' else 0\n",
    "\n",
    "print(lambda_func('Street and Sidewalk Cleaning'))\n",
    "print(lambda_func('some other string'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8477dca4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This gave us the same values as the more verbose function we defined previously, but was defined all in one line.  Now we can combine that with a pandas method called **apply** that applies our function to all the values in a column (or Series in pandas terminology)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cfe556",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['service_name'].apply(\n",
    "    lambda r: 1 if r== 'Street and Sidewalk Cleaning' else 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4240f91",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that this returns another column.  We can now save this new column as a column in our DataFrame.  We can also do this with the other string values we're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731e306e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['street_sidewalk_cleaning'] = df['service_name'].apply(\n",
    "    lambda r: 1 if r== 'Street and Sidewalk Cleaning' else 0\n",
    ")\n",
    "\n",
    "df['graffiti'] = df['service_name'].apply(\n",
    "    lambda r: 1 if r== 'Graffiti' else 0\n",
    ")\n",
    "\n",
    "df['total_cases'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7940088",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[['service_name','street_sidewalk_cleaning','graffiti','total_cases']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe13b91",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 3. Summarize By Neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dacf8cd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that we've gotten our raw data directly from the source, we can continue our transformation by summarizing the data by neighborhood.  This will allow us to join with the spatial data going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0687c3f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_neighborhood = df.groupby(\"neighborhoods_sffind_boundaries\").agg(\n",
    "    {\n",
    "        \"total_cases\": \"sum\",\n",
    "        \"street_sidewalk_cleaning\": \"sum\",\n",
    "        \"graffiti\": \"sum\"\n",
    "    }\n",
    ")\n",
    "df_neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d484dd",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 4.  Read Spatial Data and Merge with Summary Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b5d7a9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now let's create a Spatially Enabled DataFrame using neighborhood data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60227650",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sedf_neighborhoods = pandas.DataFrame.spatial.from_featureclass(\n",
    "    \"../Chapter 06/Tutorial_06_02.gdb/SF_Find_Neighborhoods\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271bc438",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We're going to use a pandas method called **merge** here.  We discuss this operation in the previous chapter, but it's basically pandas' version of a table join.  We're going to join our geometry with our summarized data and create a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaa5b50",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sedf_merge = sedf_neighborhoods.merge(\n",
    "    df_neighborhood, \n",
    "    how = 'inner', \n",
    "    left_on = 'name', \n",
    "    right_on = 'neighborhoods_sffind_boundaries'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0250057",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 5.  Write the data to an output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c29acb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The \"Load\" portion of an ETL process can take several forms.  We're going to choose to overwrite here and discuss other options following the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc47acb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sedf_merge.spatial.to_featureclass(\n",
    "    \"../Chapter 06/Tutorial_06_02.gdb/sf_311_cases_prev_7_days\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73b3856",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
