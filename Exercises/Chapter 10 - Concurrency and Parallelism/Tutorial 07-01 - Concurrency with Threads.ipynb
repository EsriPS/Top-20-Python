{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b80423e5",
   "metadata": {},
   "source": [
    "# Tutorial 07-01 - Concurrency with Threads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c729a7c1",
   "metadata": {},
   "source": [
    "Now back at our job at GeoNinjas PythonAnalytics our colleagues have gotten interested in wildfire damage to structures in California.  They've asked us to set up a process to find out how many structures could be impacted by wildfires this year.  They'd like us to make the process as fast and repeatable as possible to account for changing conditions.\n",
    "\n",
    "Let's develop a process to use ArcGIS Online to query a building footprints layer with wildfire boundaries.  We can find a dataset with current wildfire boundaries that we can use later.  For now, we can use a representative dataset like 2020 wildfires to work out the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1de228",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 1. Set up GIS object and gather data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249effe8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first thing we'll need to do is import the packages we're going to use and set up a GIS object.  This will allow us to connect to ArcGIS Online and get data from the Living Atlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7b703c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import arcgis\n",
    "import time\n",
    "\n",
    "gis = arcgis.GIS('home')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab992b3b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that we're logged in, we can search the Living Atlas and get the data we need to start our analysis.  We're going to want a layer that represents structures.  Luckily, there's a dataset called **USA Structures**.  This is a simplified polygon representation of each structure footprint in the United States greater than 450 sq ft.  We'll also need a layer of wildfires to work with.  We'll use the Living Atlas's **California Fire Perimeters 2020** layer for this.  We're going to identify them by their Item IDs, which is globally unique and the most consistent and repeatable way to identify a dataset in ArcGIS Online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9542f5d0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get the layer for USA structures\n",
    "item_id_structures = '0ec8512ad21e4bb987d7e848d14e7e24'\n",
    "item_structures = gis.content.get(item_id_structures)\n",
    "lyr_structures = item_structures.layers[0]\n",
    "\n",
    "# get the layer for 2020 wildfires\n",
    "item_id_wildfires = '37ab7a4a05ff485aba40a53deaa20ca1'\n",
    "item_wildfires = gis.content.get(item_id_wildfires)\n",
    "lyr_wildfires = item_wildfires.layers[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa7e9f0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 2. Query the structures in a single wildfire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44b31cd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's set up our logic on a single wildfire.  Then we can repeat that for all the wildfires.  First we'll need to query a specific feature from the wildfire layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5315ddcc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fset_single_wildfire = lyr_wildfires.query(\"FIRE_NAME = 'AVILA'\")\n",
    "fset_single_wildfire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e1aea0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that we've got a single wildfire feature to start with, we can create a geometry filter that we can use to query the structures layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09812dc0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get the feature from the FeatureSet\n",
    "wildfire_feature = fset_single_wildfire.features[0]\n",
    "\n",
    "# get the geometry from the single feature\n",
    "wildfire_geom = wildfire_feature.geometry\n",
    "\n",
    "# get the wildfire name\n",
    "wildfire_name = wildfire_feature.get_value(\"FIRE_NAME\")\n",
    "\n",
    "print(wildfire_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a9cf7f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's use that geometry to create a spatial filter.  We'll use the **intersects** filter in the ArcGIS API for Python's geometry module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad73629",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a spatial filter to find structures that intersect the wildfire\n",
    "wildfire_filter = arcgis.geometry.filters.intersects(\n",
    "    wildfire_geom, sr = wildfire_geom['spatialReference']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ceaefe",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can use this geometry filter to query the structures layer.  We're going to pass the geometry and only return the structures that intersect with that geometry.  As we only want the count here, we'll use the parameter *return_count_only*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c8f7f8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Query the structures layer for structures that intersect the wildfire\n",
    "structures = lyr_structures.query(\n",
    "    geometry_filter = wildfire_filter,\n",
    "    return_count_only=True\n",
    ")\n",
    "print(structures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41759712",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 3. Create a repeatable function to query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a495eb0c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We've worked out the logic we want for a single feature, but we're going to want to repeat that on many features.  It'll be good practice (especially for what's coming up) to turn that logic into a function that we can re-use.  We'll directly copy some of the code we already wrote and just change some variables to local variables.\n",
    "\n",
    "Let's also wrap all our logic in a try/except block in case anything goes wrong with a single wildfire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099c3b4c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def query_structures_by_wildfire(wildfire_feature,\n",
    "                                 structures_layer):\n",
    "    \n",
    "    try:\n",
    "        # Get the wildfire geometry and name\n",
    "        wildfire_geom = wildfire_feature.geometry\n",
    "        wildfire_name = wildfire_feature.attributes['FIRE_NAME']\n",
    "\n",
    "        # Create a spatial filter to find structures that intersect the wildfire\n",
    "        wildfire_filter = arcgis.geometry.filters.intersects(\n",
    "            wildfire_geom, sr = wildfire_geom['spatialReference']\n",
    "        )\n",
    "\n",
    "        # Query the structures layer for structures that intersect the wildfire\n",
    "        structures = structures_layer.query(\n",
    "            geometry_filter = wildfire_filter,\n",
    "            return_count_only=True\n",
    "        )\n",
    "\n",
    "        # Return the wildfire name and the number of structures\n",
    "        return {\n",
    "            'Wildfire': wildfire_name,\n",
    "            'Structures': structures\n",
    "            }\n",
    "    \n",
    "    # If an error occurs, return the wildfire name and None for the structures\n",
    "    except Exception as e:\n",
    "\n",
    "        # print the error so we know which wildfire failed\n",
    "        print(wildfire_name, e)\n",
    "\n",
    "        return {\n",
    "            'Wildfire': wildfire_name,\n",
    "            'Structures': None\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1429725d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's try out our function and make sure it works the way we intend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d602c67",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fset_single_wildfire = lyr_wildfires.query(\"FIRE_NAME = 'OAK'\")\n",
    "\n",
    "query_structures_by_wildfire(\n",
    "    wildfire_feature = fset_single_wildfire.features[0],\n",
    "    structures_layer = lyr_structures\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125af783",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 4. Repeat the query for multiple wildfires."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b19331c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's repeat this query sequentially for multiple wildfires and note the time that it takes for each.  We'll start by querying all the wildfires.  Then we'll run our query on a sample set and time the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2def0a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# query all the wildfires\n",
    "fset_wildfires = lyr_wildfires.query(\n",
    "    where = \"1=1\"\n",
    ")\n",
    "\n",
    "all_results = []\n",
    "\n",
    "# start a timer for the total time\n",
    "total_start = time.time()\n",
    "\n",
    "# iterate through the wildfires\n",
    "for wildfire in fset_wildfires.features:\n",
    "    \n",
    "    # timer for individual features\n",
    "    loop_start = time.perf_counter()\n",
    "    \n",
    "    # run the query for each wildfire\n",
    "    results = query_structures_by_wildfire(\n",
    "                            wildfire_feature = wildfire,\n",
    "                            structures_layer = lyr_structures\n",
    "                        )\n",
    "    \n",
    "    all_results.append(results)\n",
    "    \n",
    "    # close out the timer\n",
    "    loop_end = time.perf_counter()\n",
    "    \n",
    "    print(results, loop_end - loop_start)\n",
    "    \n",
    "# close out the timer for total time\n",
    "total_end = time.time()\n",
    "print(total_end - total_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cd289d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 5.  Use Threads to operate concurrently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b31b11",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In our previous step we iterated through each wildfire got our results sequentially.  Now let's say we want to speed up that process.  Since the computing of all this information is occurring on a server (and not locally) and the server is optimized for dealing with requests from many requestors, we can take advantage of that and send multiple requests at concurrently.\n",
    "\n",
    "Let's start by importing a package that's included with Python's base environment.  The **concurrent** package contains tools for handling thread-based concurrency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af09dc6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import concurrent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f452141",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are a couple important things going on in the code block below that we might not have seen before.  The first two lines creating a timestamp and an empty list are familiar enough.  We'll use that timestamp to time our workflow and see if it's faster than iterating sequentially.  The empty list is for collecting all our results.\n",
    "\n",
    "The third line of code below is where we introduce a new concept.  We're going to use a **ThreadPoolExecutor** from the concurrent package's **futures** module.  The ThreadPoolExecutor is what will handle our requests.  In our case we're allowing the ThreadPoolExecutor to manage up to ten requests concurrently (set my the *max_workers* parameter).\n",
    "\n",
    "Next, we'll iterate through each wildfire again, but this time we'll **submit** our function and parameters to the ThreadPoolExecutor (aliased as  *executor* in our script).  This is worth paying attention to because our function isn't necessarily being executed right at that moment in the iteration.  The **submit** function adds our job to the ThreadPoolExecutor's job list and returns a **future** object.  We'll append each of those futures to our empty futures list (*exec_futures*) so we can check on the status of them and retrieve the results.\n",
    "\n",
    "Once we've submitted all our requests to the ThreadPoolExecutor, we can check them to see they've finished. We can use the **as_completed** function from the concurrent package's futures module.  That will allow us ot iterate over our list of features and gather the results as they complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde5ac98",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# start a timer to time the whole operation\n",
    "mt_start = time.time()\n",
    "\n",
    "# create a list to collect all the results\n",
    "all_results = []\n",
    "\n",
    "# Use a ThreadPoolExecutor to query structures for each wildfire\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    \n",
    "    # Create a list to store the future objects\n",
    "    exec_futures = []\n",
    "\n",
    "    # Iterate through each wildfire feature\n",
    "    for wildfire in fset_wildfires.features:\n",
    "\n",
    "        # Submit a query task for each wildfire\n",
    "        exec_result = executor.submit(\n",
    "            query_structures_by_wildfire, # our function\n",
    "            wildfire_feature = wildfire, # parameters for our function\n",
    "            structures_layer = lyr_structures\n",
    "        )\n",
    "\n",
    "        # Append the future object to the list\n",
    "        exec_futures.append(exec_result)\n",
    "\n",
    "    # Iterate through the future objects as they complete\n",
    "    for f in concurrent.futures.as_completed(exec_futures):\n",
    "        all_results.append(f.result())\n",
    "\n",
    "# End timer and print the total time\n",
    "mt_end = time.time()\n",
    "print(mt_end - mt_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dbfb16",
   "metadata": {
    "hidden": true
   },
   "source": [
    "That was a bit more complicated than just iterating through all the wildfires sequentially.  It might not have seemed like it was worth it as we were getting into it.  After all, each of these query operations doesn't necessarily take all that long.  After comparing the durations of steps 4 and 5 though, we can see that operating concurrently made a significant reduction in our runtime.  On my environment, step 5 took about one third of the time that step 4 took.\n",
    "\n",
    "As a final step, we can turn our results into a DataFrame and pass that on to whatever downstream consumers we might have.  Check out the chapter on Data Engineering for potential next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05069b34",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "df = pandas.DataFrame(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c266684f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4c54cb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
