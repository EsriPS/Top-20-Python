{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b80423e5",
   "metadata": {},
   "source": [
    "# Tutorial 10-01 - Concurrency with Threads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c729a7c1",
   "metadata": {},
   "source": [
    "Now back at our job at GeoNinjas PythonAnalytics our colleagues have gotten interested in wildfire damage to structures in California.  They've asked us to set up a process to find out how many structures could be impacted by wildfires this year.  They'd like us to make the process as fast and repeatable as possible to account for changing conditions.\n",
    "\n",
    "Let's develop a process to use ArcGIS Online to query a building footprints layer with wildfire boundaries.  We can find a dataset with current wildfire boundaries that we can use later.  For now, we can use a representative dataset like 2020 wildfires to work out the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1de228",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Set up GIS object and gather data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a4d809",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 1.  Import packages and set up a GIS object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249effe8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first thing you'll need to do is import the packages you're going to use and set up a GIS object.  This will allow you to connect to ArcGIS Online and get data from the Living Atlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7b703c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import arcgis\n",
    "import time\n",
    "\n",
    "gis = arcgis.GIS('home')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c051fa",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 2.  Find structure and wildfire data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab992b3b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that you're logged in, you can search the Living Atlas and get the data we need to start your analysis.  You're going to want a layer that represents structures.  Luckily, there's a dataset called **USA Structures**.  This is a simplified polygon representation of each structure footprint in the United States greater than 450 sq ft.  You'll also need a layer of wildfires to work with.  You'll use the Living Atlas's **California Fire Perimeters 2020** layer for this.  You're going to identify them by their Item IDs, which is globally unique and the most consistent and repeatable way to identify a dataset in ArcGIS Online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9542f5d0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get the layer for USA structures\n",
    "item_id_structures = '0ec8512ad21e4bb987d7e848d14e7e24'\n",
    "item_structures = gis.content.get(item_id_structures)\n",
    "lyr_structures = item_structures.layers[0]\n",
    "\n",
    "# get the layer for 2020 wildfires\n",
    "item_id_wildfires = '37ab7a4a05ff485aba40a53deaa20ca1'\n",
    "item_wildfires = gis.content.get(item_id_wildfires)\n",
    "lyr_wildfires = item_wildfires.layers[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa7e9f0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Query the structures in a single wildfire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44b31cd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "First, it's a good idea to set up your logic on a single wildfire.  Then you can repeat that for all the wildfires.  First you'll need to query a specific feature from the wildfire layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d9a542",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 1.  Query a single wildfire feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258abdec",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Pick a wildfire to start with.  In this case, we've chosen an example fire from the beginning alphabetically.  Picking the first one that comes up would be totally valid too.  You just need one to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5315ddcc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fset_single_wildfire = lyr_wildfires.query(\"FIRE_NAME = 'AVILA'\")\n",
    "fset_single_wildfire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e1aea0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that you've got a single wildfire feature to start with, you can create a geometry filter that we can use to query the structures layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078a4773",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 2.  Access a single feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5ab3e1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "When you queried for a single feature, what you got as a response was a `FeatureSet` object.  This object has some descriptive information about the dataset such as the spatial reference and fields.  In this specific use case, however, you're just interested in the first feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c7927a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get the feature from the FeatureSet\n",
    "wildfire_feature = fset_single_wildfire.features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730da214",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 3.  Access the geometry and attributes of a feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6548c4dc",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You can access both the geometry and attribute data of a feature.  To access the geometry (which we'll use for a spatial filter) you can call the `.geometry` property of a feature.  To access attribute data of a feature, you can call the `.get_value()` method and provide a field name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09812dc0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get the geometry from the single feature\n",
    "wildfire_geom = wildfire_feature.geometry\n",
    "\n",
    "# get the wildfire name\n",
    "wildfire_name = wildfire_feature.get_value(\"FIRE_NAME\")\n",
    "\n",
    "print(wildfire_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58dc4f1",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 4.  Create a spatial filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a9cf7f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You can use that geometry to create a spatial filter.  You'll use the **intersects** filter in the ArcGIS API for Python's geometry module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad73629",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a spatial filter to find structures that intersect the wildfire\n",
    "wildfire_filter = arcgis.geometry.filters.intersects(\n",
    "    wildfire_geom, sr = wildfire_geom['spatialReference']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4a3ac9",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 5.  Use the spatial filter to query the structures layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ceaefe",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You can use this geometry filter to query the structures layer.  You're going to pass the geometry filter as a query parameter and only return the structures that intersect with that geometry.  As we only want the count here, you'll use the parameter *return_count_only*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c8f7f8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Query the structures layer for structures that intersect the wildfire\n",
    "structures = lyr_structures.query(\n",
    "    geometry_filter = wildfire_filter,\n",
    "    return_count_only=True\n",
    ")\n",
    "print(structures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41759712",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create a repeatable function to query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940b52a4",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 1.  Re-structure your code as a function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a495eb0c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You've worked out the logic we want for a single feature, but you're going to want to repeat that on many features.  It'll be good practice (especially for what's coming up) to turn that logic into a function that you can re-use.  You'll directly copy some of the code we already wrote and just change some variables to local variables.\n",
    "\n",
    "It's also a good idea wrap all our logic in a try/except block in case anything goes wrong with a single wildfire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099c3b4c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def query_structures_by_wildfire(wildfire_feature,\n",
    "                                 structures_layer):\n",
    "    \n",
    "    try:\n",
    "        # Get the wildfire geometry and name\n",
    "        wildfire_geom = wildfire_feature.geometry\n",
    "        wildfire_name = wildfire_feature.attributes['FIRE_NAME']\n",
    "\n",
    "        # Create a spatial filter to find structures that intersect the wildfire\n",
    "        wildfire_filter = arcgis.geometry.filters.intersects(\n",
    "            wildfire_geom, sr = wildfire_geom['spatialReference']\n",
    "        )\n",
    "\n",
    "        # Query the structures layer for structures that intersect the wildfire\n",
    "        structures = structures_layer.query(\n",
    "            geometry_filter = wildfire_filter,\n",
    "            return_count_only=True\n",
    "        )\n",
    "\n",
    "        # Return the wildfire name and the number of structures\n",
    "        return {\n",
    "            'Wildfire': wildfire_name,\n",
    "            'Structures': structures\n",
    "            }\n",
    "    \n",
    "    # If an error occurs, return the wildfire name and None for the structures\n",
    "    except Exception as e:\n",
    "\n",
    "        # print the error so we know which wildfire failed\n",
    "        print(wildfire_name, e)\n",
    "\n",
    "        return {\n",
    "            'Wildfire': wildfire_name,\n",
    "            'Structures': None\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1582877",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 2.  Test the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1429725d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now you can try out your function and ensure it returns the results you expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d602c67",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fset_single_wildfire = lyr_wildfires.query(\"FIRE_NAME = 'OAK'\")\n",
    "\n",
    "query_structures_by_wildfire(\n",
    "    wildfire_feature = fset_single_wildfire.features[0],\n",
    "    structures_layer = lyr_structures\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125af783",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Repeat the query for multiple wildfires."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b19331c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's repeat this query sequentially for multiple wildfires and note the time that it takes for each.  We'll start by querying all the wildfires.  Then we'll run our query on a sample set and time the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2e709f",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 1.  Query all the wildfires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eddae36",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Similarly to how you queried a single wildfire, you can query all the wildfires in one operation.  Then you can iterate through the `.features` of the resulting `FeatureSet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced3f1a4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# query all the wildfires\n",
    "fset_wildfires = lyr_wildfires.query(\n",
    "    where = \"1=1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efedaa6",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 2.  Loop through each wildfire feature and query structure data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951127d8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now you'll use a for loop too repeat this query on with each wildfire.  In the code block below, there are some extra lines of code to time the operation.  In addition to timing the entire operation, there's some code to time the query operation for each wildfire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2def0a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "all_results = []\n",
    "\n",
    "# start a timer for the total time\n",
    "total_start = time.time()\n",
    "\n",
    "# iterate through the wildfires\n",
    "for wildfire in fset_wildfires.features:\n",
    "    \n",
    "    # timer for individual features\n",
    "    loop_start = time.perf_counter()\n",
    "    \n",
    "    # run the query for each wildfire\n",
    "    results = query_structures_by_wildfire(\n",
    "                            wildfire_feature = wildfire,\n",
    "                            structures_layer = lyr_structures\n",
    "                        )\n",
    "    \n",
    "    all_results.append(results)\n",
    "    \n",
    "    # close out the timer\n",
    "    loop_end = time.perf_counter()\n",
    "    \n",
    "    print(results, loop_end - loop_start)\n",
    "    \n",
    "# close out the timer for total time\n",
    "total_end = time.time()\n",
    "print(total_end - total_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cd289d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Use Threads to operate concurrently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b31b11",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In the previous step you iterated through each wildfire got our results sequentially.  Now let's say we want to speed up that process.  Since the computing of all this information is occurring on a server (and not locally) and the server is optimized for dealing with requests from many requestors, we can take advantage of that and send multiple requests at concurrently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e800ba",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  1.  Import the concurrent package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb223240",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You can start by importing a package that's included with Python's base environment.  The **concurrent** package contains tools for handling thread-based concurrency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af09dc6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import concurrent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f451bc",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 2.  Implement multithreading with the concurrent package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f452141",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are a couple important things going on in the code block below that you might not have seen before.  The first two lines creating a timestamp and an empty list are familiar enough.  You'll use that timestamp to time your workflow and see if it's faster than iterating sequentially.  The empty list is for collecting all our results.\n",
    "\n",
    "The third line of code below is where we introduce a new concept.  You're going to use a **ThreadPoolExecutor** from the concurrent package's **futures** module.  The ThreadPoolExecutor is what will handle your requests.  In our case you're allowing the ThreadPoolExecutor to manage up to ten requests concurrently (set by the `max_workers` parameter).\n",
    "\n",
    "Next, you'll iterate through each wildfire again, but this time you'll `submit` your function and parameters to the ThreadPoolExecutor (aliased as  *executor* in this script).  This is worth paying attention to because the function isn't necessarily being executed right at that moment in the iteration.  The `submit` method adds our job to the ThreadPoolExecutor's job list and returns a **future** object.  You'll append each of those futures to our empty futures list (*exec_futures*) so you can check on the status of them and retrieve the results.\n",
    "\n",
    "Once we've submitted all our requests to the ThreadPoolExecutor, you can check them to see they've finished. You can use the `as_completed` function from the concurrent package's futures module.  That will allow you iterate over our list of futures and gather the results as they complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde5ac98",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# start a timer to time the whole operation\n",
    "mt_start = time.time()\n",
    "\n",
    "# create a list to collect all the results\n",
    "all_results = []\n",
    "\n",
    "# Use a ThreadPoolExecutor to query structures for each wildfire\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    \n",
    "    # Create a list to store the future objects\n",
    "    exec_futures = []\n",
    "\n",
    "    # Iterate through each wildfire feature\n",
    "    for wildfire in fset_wildfires.features:\n",
    "\n",
    "        # Submit a query task for each wildfire\n",
    "        exec_result = executor.submit(\n",
    "            query_structures_by_wildfire, # our function\n",
    "            wildfire_feature = wildfire, # parameters for our function\n",
    "            structures_layer = lyr_structures\n",
    "        )\n",
    "\n",
    "        # Append the future object to the list\n",
    "        exec_futures.append(exec_result)\n",
    "\n",
    "    # Iterate through the future objects as they complete\n",
    "    for f in concurrent.futures.as_completed(exec_futures):\n",
    "        all_results.append(f.result())\n",
    "\n",
    "# End timer and print the total time\n",
    "mt_end = time.time()\n",
    "print(mt_end - mt_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dbfb16",
   "metadata": {
    "hidden": true
   },
   "source": [
    "That was a bit more complicated than just iterating through all the wildfires sequentially.  It might not have seemed like it was worth it as you were getting into it.  After all, each of these query operations doesn't necessarily take all that long.  After comparing the durations of the sequential (for loop) and concurrent executions though, you can see that operating concurrently made a significant reduction in runtime.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5165045",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 3.  Package results as a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b81c3ea",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As a final step, You can turn our results into a DataFrame and pass that on to whatever downstream consumers you might have.  Check out the chapter on Data Engineering for potential next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05069b34",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "df = pandas.DataFrame(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c266684f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4c54cb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
